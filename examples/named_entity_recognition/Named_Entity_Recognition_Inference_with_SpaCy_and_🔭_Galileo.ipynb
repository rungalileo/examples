{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "j5JVjGAAJOTn"
   },
   "source": [
    "# Inference Named Entity Recognition with SpaCy and üî≠ Galileo\n",
    "\n",
    "In this tutorial, we'll log an inference dataset on a pre-trained model with SpaCy and explore the results in Galileo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "UfMcPbg19uz1"
   },
   "outputs": [],
   "source": [
    "#@title Install `dataquality` and other dependencies\n",
    "\n",
    "# Upgrade pip\n",
    "!pip install -U pip &> /dev/null\n",
    "# Install HF datasets for downloading the example datasets\n",
    "!pip install -U dataquality datasets \"spacy==3.2.1\" &> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9QyHXYMZJw3H"
   },
   "source": [
    "# Login to Galileo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GALILEO_CONSOLE_URL_ENTERPRISE\"] = \"https://console.enterprise-a.rungalileo.io\"\n",
    "os.environ[\"GALILEO_USERNAME_ENTERPRISE\"] = \"david@rungalileo.io\"\n",
    "os.environ[\"GALILEO_PASSWORD_ENTERPRISE\"] = \"ufz2ytz@eby2MRF2djy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1rFe0jpme1fR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì° https://console.enterprise-a.rungalileo.io\n",
      "üî≠ Logging you into Galileo\n",
      "\n",
      "üöÄ You're logged in to Galileo as david@rungalileo.io!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import dataquality as dq\n",
    "import spacy\n",
    "\n",
    "# TODO: Set enterprise env variables\n",
    "os.environ[\"GALILEO_CONSOLE_URL\"] = os.getenv(\"GALILEO_CONSOLE_URL_ENTERPRISE\")  # Update\n",
    "os.environ[\"GALILEO_USERNAME\"] = os.getenv(\"GALILEO_USERNAME_ENTERPRISE\")  # Update\n",
    "os.environ[\"GALILEO_PASSWORD\"] = os.getenv(\"GALILEO_PASSWORD_ENTERPRISE\")  # Update\n",
    "\n",
    "dq.configure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "atuhn2xgB_ct"
   },
   "source": [
    "# Inference DataSet Preparation \n",
    "We load text samples from HuggingFaceü§ó dataset. This data can be thought of as production data that our model is making predictions on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "id": "xWBoiMrseLKY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You selected the conllpp dataset\n",
      "\n",
      "üèÜ Dataset conllpp loaded succesfully\n"
     ]
    }
   ],
   "source": [
    "#@title ü§ó HuggingFace Dataset\n",
    "#@markdown You can select any dataset from [here](https://huggingface.co/datasets?language=language:en&task_categories=task_categories:token-classification&task_ids=task_ids:named-entity-recognition&sort=downloads).\n",
    "\n",
    "dataset_name = 'conllpp' #@param [\"wnut_17\", \"conllpp\", \"wikiann\"] {allow-input: true}\n",
    "print(f\"You selected the {dataset_name} dataset\")\n",
    "\n",
    "from IPython.utils import io\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset, get_dataset_config_names\n",
    "\n",
    "# Try to load the data. If a config (subset) is needed, pick one\n",
    "try:\n",
    "  with io.capture_output() as captured:\n",
    "    data = load_dataset(dataset_name)\n",
    "except ValueError as e:\n",
    "  if \"Config name is missing\" not in repr(e):\n",
    "    raise e\n",
    "\n",
    "  configs = get_dataset_config_names(dataset_name)\n",
    "  print(f\"The dataset {dataset_name} has multiple subsets {configs}.\")\n",
    "  config = input(f\"üññ Enter the name of the subset to pick (or leave blank for any): \")\n",
    "  if config:\n",
    "    assert config in configs, f\"{config} is not a valid subset\"\n",
    "  else:\n",
    "    config = configs[0]\n",
    "  with io.capture_output() as captured:\n",
    "    data = load_dataset(dataset_name, name=config)\n",
    "\n",
    "# Check that the dataset has at least a validation/test set to use as inference data\n",
    "assert {\"validation\", \"test\"}.intersection(data), \\\n",
    "f\"üíæ The dataset {dataset_name} has no validation or test splits, select another one.\"\n",
    "\n",
    "print(f\"\\nüèÜ Dataset {dataset_name} loaded succesfully\")\n",
    "\n",
    "# A small function for minimizing the dataset for testing\n",
    "import os\n",
    "\n",
    "def _minimize_for_ci() -> bool:\n",
    "    return True\n",
    "    # return os.getenv(\"MINIMIZE_FOR_CI\", \"false\") == \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference_docs(data, nlp) -> list:\n",
    "    # Get inference split name\n",
    "    inf_split_name = \"validation\" if \"validation\" in data else \"test\"\n",
    "    tokens = data[inf_split_name]['tokens']\n",
    "    text_inputs = [' '.join(_tokens) for _tokens in tokens]\n",
    "\n",
    "    if _minimize_for_ci():\n",
    "        text_inputs = text_inputs[:50]\n",
    "\n",
    "    # Get inference docs\n",
    "    inference_docs = [nlp.make_doc(text) for text in text_inputs]\n",
    "\n",
    "    return inference_docs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model\n",
    "\n",
    "Inference data can be logged as part of an existing run with previously logged training, validation, and test splits, or it can be logged in isolation.\n",
    "\n",
    "If you want to access the full suite of inference features, including automated drift detection, first run the [NER Spacy and Galileo training notebook](https://colab.research.google.com/github/rungalileo/examples/blob/main/examples/named_entity_recognition/Named_Entity_Recognition_with_SpaCy_and_%F0%9F%94%AD_Galileo.ipynb#scrollTo=QkUoYnK0oFK_).\n",
    "\n",
    "Otherwise, we will download a small pretrained model to use for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "inference_only = True #@param [True, False] {allow-input: false}\n",
    "\n",
    "if inference_only:\n",
    "    # Download a small English model for running inference\n",
    "    !python -m spacy download en_core_web_sm &> /dev/null\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "else:\n",
    "    # Load trained model from NER Spacy training notebook\n",
    "    nlp = spacy.load(\"my_model\")  # TODO: Update path to model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference with Galileo\n",
    "Inference samples are logged to Galileo using `log_input_docs`. Model data is logged by wrapping the `nlp` object using `watch`. This automatically logs the logits and embeddings from your model to Galileo with just 1 line of code. \n",
    "\n",
    "We complete the inference pipeline by setting the split to `inference` and then passing inference Doc objects through our `nlp` model. To complete logging, we call `dq.finish()` after logging inference data.\n",
    "\n",
    "Each inference run must have a unique `inference_name` that must be consistent for input and model logs. You can log multiple inference datasets with different `inference_name`s on the same Project/Run pair.\n",
    "\n",
    "**Note:** If you want to connect this inference run to an existing training run, make sure to use the same `project_name` and `run_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì° Retrieving run from existing project, named_entity_recognition_spacy\n",
      "üõ∞ Connected to project, named_entity_recognition_spacy, and run, example_run_conllpp.\n",
      "Logging 50 samples [########################################] 100.00% elapsed time  :     0.01s =  0.0m =  0.0h\n",
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elliottchartock/Code/examples/.venv/lib/python3.9/site-packages/dataquality/core/init.py:178: UserWarning: Run: named_entity_recognition_spacy/example_run_conllpp already exists! The existing run will get overwritten on call to finish()!\n",
      "  warnings.warn(\n",
      "/Users/elliottchartock/Code/examples/.venv/lib/python3.9/site-packages/dataquality/loggers/model_logger/base_model_logger.py:67: GalileoWarning: An error occurred logging this batch, it will be skipped. Error: No samples in this batch had any gold or prediction spans. Logging will be skipped\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚òÅÔ∏è Uploading Data\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006643772125244141,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 33,
       "postfix": null,
       "prefix": "inference",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea8144c2ee614fa589ae2f97753c0070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0065610408782958984,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 33,
       "postfix": null,
       "prefix": "Processing data for upload",
       "rate": null,
       "total": 47,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing data for upload:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00615692138671875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 33,
       "postfix": null,
       "prefix": "inference (inf_name=example1)",
       "rate": null,
       "total": 3,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "inference (inf_name=example1):   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008237123489379883,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 33,
       "postfix": null,
       "prefix": "Uploading data to Galileo",
       "rate": null,
       "total": 58648,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading data to Galileo:   0%|          | 0.00/57.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008505821228027344,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 33,
       "postfix": null,
       "prefix": "Uploading data to Galileo",
       "rate": null,
       "total": 140014,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading data to Galileo:   0%|          | 0.00/137k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008268117904663086,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 33,
       "postfix": null,
       "prefix": "Uploading data to Galileo",
       "rate": null,
       "total": 22928,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading data to Galileo:   0%|          | 0.00/22.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job inference successfully submitted. Results will be available soon at https://console.enterprise-a.rungalileo.io/insights?projectId=13ab66e6-dd33-4d00-b2d1-fb971f97ba2e&runId=5cc6e2dc-e029-4bfc-acee-501b7d53d24d&split=training&metric=f1&depHigh=1&depLow=0&taskType=2\n",
      "Waiting for job...\n",
      "\tLooking for training data\n",
      "Done! Job finished with status completed\n",
      "Click here to see your run! https://console.enterprise-a.rungalileo.io/insights?projectId=13ab66e6-dd33-4d00-b2d1-fb971f97ba2e&runId=5cc6e2dc-e029-4bfc-acee-501b7d53d24d&split=training&metric=f1&depHigh=1&depLow=0&taskType=2\n",
      "üßπ Cleaning up\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from dataquality.integrations.spacy import log_input_docs, unwatch, watch\n",
    "\n",
    "# üî≠üåï Initializing a new run in Galileo. Each run is part of a project.\n",
    "dq.init(task_type=\"text_ner\", \n",
    "        project_name=\"named_entity_recognition_spacy\", \n",
    "        run_name=f\"example_run_{dataset_name.replace('/', '-')}\")\n",
    "\n",
    "inference_docs = get_inference_docs(data, nlp)\n",
    "inference_name = \"example1\"\n",
    "meta = {\n",
    "    \"color\": random.choices([\"red\", \"blue\", \"green\"], k=len(inference_docs)),\n",
    "    \"ranking\": random.choices(range(1,101), k=len(inference_docs))\n",
    "}\n",
    "\n",
    "watch(nlp) # üî≠üåï One line of Galileo code to capture the model's predictions on the inputs\n",
    "log_input_docs(inference_docs, inference_name=inference_name, meta=meta) # üî≠üåï Logging the inference docs with Galileo\n",
    "\n",
    "dq.set_split(\"inference\", inference_name=inference_name)\n",
    "for doc in inference_docs:\n",
    "    nlp(doc)\n",
    "\n",
    "dq.finish()\n",
    "unwatch(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V9o7ZwZVZIiM"
   },
   "outputs": [],
   "source": [
    "dq.get_data_logger().doc()\n",
    "help(dq.log_dataset)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "1IQ99tSgicpVpCrkhjTp-Dp_f2ucBhvy3",
     "timestamp": 1659469611341
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "a233f9af8164ad7126959a4556cea8249e0fb02fb25eacb38c78037d5824a315"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
