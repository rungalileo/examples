{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtrzsybpftNu"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/rungalileo/examples/blob/notebooks/trainer/examples/named_entity_recognition/pytorch.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5JVjGAAJOTn"
      },
      "source": [
        "# Named Entity Recognition with Pytorch and üî≠ Galileo\n",
        "\n",
        "In this tutorial, we'll train a model with PyTorch and explore the results in Galileo.\n",
        "\n",
        "**Make sure to select GPU in your Runtime! (Runtime -> Change Runtime type)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CO_8j8NVr6aF"
      },
      "outputs": [],
      "source": [
        "!pip install torchdata seqeval\n",
        "!pip install vaex vaex-core vaex-hdf5 datasets evaluate responses\\<0.19 --no-deps  -q\n",
        "!pip install diskcache==5.2.1 gorilla==0.3.0 resource==0.2.1 types-requests==2.25.2 transformers==4.22.2 multiprocess  xxhash blake3 aplus frozendict!=2.2.0 nest-asyncio\\>=1.3.3 rich jedi -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf dataquality\n",
        "# Install all dependecies\n",
        "!git clone https://galileo-automation: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@github.com/rungalileo/dataquality.git --branch feature/torch-simplification"
      ],
      "metadata": {
        "id": "iakQv6qMf9h_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7_i5cCyt12N"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "\n",
        "%autoreload 2\n",
        "\n",
        "import sys\n",
        "sys.path.insert(1, \"./dataquality\")\n",
        "\n",
        "import os \n",
        "import dataquality as dq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"GALILEO_CONSOLE_URL\"] = \"https://console.dev.rungalileo.io/\"\n",
        "dq.configure()\n",
        "dq.login()"
      ],
      "metadata": {
        "id": "Ue7prXzDgRwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QyHXYMZJw3H"
      },
      "source": [
        "# 1. Login to Galileo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOKPfMhYvgeL"
      },
      "source": [
        "# 2. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXKeZqJRCakz"
      },
      "outputs": [],
      "source": [
        "#@title ü§ó HuggingFace Dataset\n",
        "#@markdown You can select any dataset from [here](https://huggingface.co/datasets?language=language:en&task_categories=task_categories:token-classification&task_ids=task_ids:named-entity-recognition&sort=downloads) which contains train/validation/test splits and an `ner_tags` column.\n",
        "\n",
        "dataset_name = 'conllpp' #@param [\"wnut_17\", \"conllpp\", \"wikiann\"] {allow-input: true}\n",
        "print(f\"You selected the {dataset_name} dataset\")\n",
        "\n",
        "from IPython.utils import io\n",
        "from datasets import load_dataset, get_dataset_config_names\n",
        "\n",
        "# Try to load the data. If a config (subset) is needed, pick one\n",
        "try:\n",
        "  with io.capture_output() as captured:\n",
        "    dataset = load_dataset(dataset_name)\n",
        "except ValueError as e:\n",
        "  if \"Config name is missing\" not in repr(e):\n",
        "    raise e\n",
        "\n",
        "  configs = get_dataset_config_names(dataset_name)\n",
        "  print(f\"The dataset {dataset_name} has multiple subsets {configs}.\")\n",
        "  config = input(f\"üññ Enter the name of the subset to pick (or leave blank for any): \")\n",
        "  if config:\n",
        "    assert config in configs, f\"{config} is not a valid subset\"\n",
        "  else:\n",
        "    config = configs[0]\n",
        "  with io.capture_output() as captured:\n",
        "    dataset = load_dataset(dataset_name, name=config)\n",
        "\n",
        "# Check that the dataset has at least train and validation splits\n",
        "assert {\"train\", \"validation\", \"test\"}.issubset(dataset), \\\n",
        "f\"üíæ The dataset {dataset_name} does no have train/validation splits, please pick another one.\"\n",
        "\n",
        "print(f\"\\nüèÜ Dataset {dataset_name} loaded succesfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IggxTe4l6yCY"
      },
      "source": [
        "# 3. Initialize Galileo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zhh822b56xWE"
      },
      "outputs": [],
      "source": [
        "# üî≠üåï Initializing a new run in Galileo. Each run goes under a project.\n",
        "dq.init(task_type=\"text_ner\", \n",
        "        project_name=\"named_entity_recognition_pytorch\", \n",
        "        run_name=f\"example_run_{dataset_name.replace('/','-')}_15\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyMCfBzyvMzc"
      },
      "source": [
        "# 4. Tokenize and Log Dataset\n",
        "Galileo provides HF integrations to allow tokenization, and label alignment, while automatically logging your input data. Additionally, you can also use the `get_dataloader` function instead of PyTorch's native `DataLoader` to autoatically create a `Dataset` class, and prepare a dataset loader for each split.  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dataquality.integrations import hf\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('roberta-base', add_prefix_space=True)\n",
        "\n",
        "# üî≠üåï Galileo tokenizes the HuggingFace DatasetDict logs the dataset(s) present in it\n",
        "tokenized_datasets = hf.tokenize_and_log_dataset(data, tokenizer)\n",
        "labels = tokenized_datasets['train'].features['ner_tags'].feature.names  \n"
      ],
      "metadata": {
        "id": "viY7TeP-nOyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kqOV9V5wl4J"
      },
      "source": [
        "# 5. Prepare and Log NER Model \n",
        "\n",
        "One line of Galileo code to log the NER Model data (via `log_model_outputs`). This step logs the model logits and embeddings. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEVmYug7wqCc"
      },
      "outputs": [],
      "source": [
        "\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
        "from transformers import AutoModelForTokenClassification\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from datasets import load_dataset, load_metric\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "metric = load_metric('seqeval')\n",
        "model = AutoModelForTokenClassification.from_pretrained('roberta-base', num_labels=len(label_list), id2label=id2label, label2id=label2id, finetuning_task=\"ner\")\n",
        "batch_size = 10\n",
        "\n",
        "task = \"ner\"\n",
        "label_list = dataset['train'].features['ner_tags'].feature.names\n",
        "id2label = {idx:label for idx, label in enumerate(label_list)}\n",
        "label2id = {label:idx for idx, label in id2label.items()}\n",
        "label_all_token = True\n",
        "\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    # Remove ignored index (special tokens)\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"],\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "args = TrainingArguments(\n",
        "    f\"tesk-{task}\",\n",
        "    evaluation_strategy='epoch',\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy='epoch',\n",
        "    logging_strategy='epoch',\n",
        "    logging_dir='./logs'\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation'],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMV9XnJaSg9j"
      },
      "source": [
        "# 6. Putting into Action: Training a Model\n",
        "\n",
        "Complete the training pipeline using a standard PyTorch training setup. While training, Galileo logs the current `epoch` and `split`. \n",
        "\n",
        "Call `dq.finish()` after training to complete the logging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kvfEg4cnzTZ"
      },
      "outputs": [],
      "source": [
        "from dataquality.integrations.transformers_trainer import watch\n",
        "\n",
        "# üî≠üåï Galileo Logging\n",
        "watch(trainer)\n",
        "\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# üî≠üåï Galileo Logging\n",
        "dq.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkUoYnK0oFK_"
      },
      "source": [
        "# General Help and Docs\n",
        "- To get help with your task's requirements, call `dq.get_data_logger().doc()`\n",
        "- To see more general data and model logging docs, run `dq.docs()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "V9o7ZwZVZIiM"
      },
      "outputs": [],
      "source": [
        "dq.get_data_logger().doc()\n",
        "help(dq.log_dataset)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}