{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5JVjGAAJOTn"
      },
      "source": [
        "# Multi Label Text Classification using Pytorch and üî≠ Galileo\n",
        "\n",
        "In this tutorial, we'll train a model with PyTorch and explore the results in Galileo.\n",
        "\n",
        "**Make sure to select GPU in your Runtime! (Runtime -> Change Runtime type)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "UfMcPbg19uz1"
      },
      "outputs": [],
      "source": [
        "#@title Install `dataquality`\n",
        "try:\n",
        "    import dataquality as dq\n",
        "except ImportError:\n",
        "    # Upgrade pip\n",
        "    !pip install -U pip &> /dev/null\n",
        "\n",
        "    # Install all dependecies\n",
        "    !pip install -U dataquality torch torchmetrics datasets transformers &> /dev/null\n",
        "    \n",
        "    print('üëã Installed necessary libraries and restarting runtime! This should only need to happen once.')\n",
        "    print('üôè Continue with the rest of the notebook or hit \"Run All\" again!')\n",
        "\n",
        "    # Restart the runtime\n",
        "    import os, time\n",
        "    time.sleep(1) # gives the print statements time to flush\n",
        "    os._exit(0) # exits without allowing the next cell to run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QyHXYMZJw3H"
      },
      "source": [
        "# 1. Login to Galileo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pO6DdYFob5UV"
      },
      "outputs": [],
      "source": [
        "import dataquality as dq\n",
        "\n",
        "dq.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOKPfMhYvgeL"
      },
      "source": [
        "# 2. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "AVBx_6P4PeLg"
      },
      "outputs": [],
      "source": [
        "#@title ü§ó HuggingFace Dataset\n",
        "#@markdown You can find more datasets [here](https://huggingface.co/datasets?language=language:en&task_categories=task_categories:text-classification&task_ids=task_ids:multi-label-classification&sort=downloads).\n",
        "\n",
        "dataset_name = 'lex_glue' #@param [\"go_emotions\", \"lex_glue\"] {allow-input: true}\n",
        "print(f\"You selected the {dataset_name} dataset\")\n",
        "\n",
        "from IPython.utils import io\n",
        "from datasets import load_dataset, get_dataset_config_names\n",
        "\n",
        "# Try to load the data. If a config (subset) is needed, pick one\n",
        "try:\n",
        "  with io.capture_output() as captured:\n",
        "    data = load_dataset(dataset_name)\n",
        "except ValueError as e:\n",
        "  if \"Config name is missing\" not in repr(e):\n",
        "    raise e\n",
        "\n",
        "  configs = get_dataset_config_names(dataset_name)\n",
        "  print(f\"The dataset {dataset_name} has multiple subsets {configs}.\")\n",
        "  config = input(f\"üññ Enter the name of the subset to pick (or leave blank for any): \")\n",
        "  if config:\n",
        "    assert config in configs, f\"{config} is not a valid subset\"\n",
        "  else:\n",
        "    config = configs[0]\n",
        "  with io.capture_output() as captured:\n",
        "    data = load_dataset(dataset_name, name=config)\n",
        "\n",
        "\n",
        "# Check that the dataset has at least train and either of validation/test\n",
        "assert \"train\" in data and {\"validation\", \"test\"}.intersection(data), \\\n",
        "f\"üíæ The dataset {dataset_name} has either no train, or no validation or test splits, select another one.\"\n",
        "\n",
        "print(f\"\\nüèÜ Dataset {dataset_name} loaded succesfully\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3yKR4e9d3xa"
      },
      "outputs": [],
      "source": [
        "#@markdown Convert HF dataset to Pandas dataframes \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def load_pandas_df(data):\n",
        "  # Find the name of the ground truth column\n",
        "  good_col_names = [name for name in list(data['train'].features) if \"label\" in name]\n",
        "  if len(good_col_names) == 1:\n",
        "    label_col = good_col_names[0]\n",
        "  else:\n",
        "    col_names = list(data['train'].features)\n",
        "    print(f\"The name of the columns are {col_names}.\")\n",
        "    label_col = input(f\"üèÖ Please enter the name of the column containing the labels: \")\n",
        "    assert label_col in col_names, f\"{label_col} is not an existing column\"\n",
        "\n",
        "  # Load the labels in a dictionary\n",
        "  num_classes = len(data['train'].features[label_col].feature.names)\n",
        "  labels_cols = data['train'].features[label_col].feature.int2str(range(0, num_classes))\n",
        "\n",
        "  def binarize_label_indices(label_idxs):\n",
        "    a = np.zeros(len(labels_cols), dtype=int)\n",
        "    a[label_idxs] = 1\n",
        "    return a\n",
        "\n",
        "  # Load the train data into a frame\n",
        "  train_data = data[\"train\"]\n",
        "  train_df = pd.DataFrame.from_dict(train_data)\n",
        "  train_labels = list(map(binarize_label_indices, data['train'][label_col]))\n",
        "  _train_df_labels = pd.DataFrame(train_labels, columns=labels_cols)\n",
        "  train_df = pd.concat([train_df, _train_df_labels], axis=1)\n",
        "  train_df['id'] = train_df.index\n",
        "\n",
        "  # Load the test data into a frame\n",
        "  test_split_name = \"validation\" if \"validation\" in data else \"test\"\n",
        "  test_data = data[test_split_name]\n",
        "  test_df = pd.DataFrame.from_dict(test_data)\n",
        "  test_labels = list(map(binarize_label_indices, data[test_split_name][label_col]))\n",
        "  _test_df_labels = pd.DataFrame(test_labels, columns=labels_cols)\n",
        "  test_df = pd.concat([test_df, _test_df_labels], axis=1)\n",
        "  test_df['id'] = test_df.index\n",
        "  \n",
        "  return train_df, test_df, labels_cols\n",
        "\n",
        "# data = load_dataset(hf_dataset)\n",
        "train_df, test_df, labels_cols = load_pandas_df(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRYWE35jPxUA"
      },
      "source": [
        "# 3. Initialize Galileo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5mbCGnhPbGy"
      },
      "outputs": [],
      "source": [
        "# üî≠üåï Galileo logging\n",
        "dq.init(task_type=\"text_multi_label\", \n",
        "        project_name=\"multi_label_text_classification_pytorch\", \n",
        "        run_name=f\"example_run_{dataset_name.replace('/', '-')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zJHmvxTJ2pN"
      },
      "source": [
        "# 4. Log input data with Galileo\n",
        "Input data can be logged via `log_data_samples` (or `log_dataset` for logging iterables). This step will log input samples, gold labels, data split, and list of all labels. You can achieve this by adding 1 line of code to the standard PyTorch Dataset Class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FX8KsPk_m6Au"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from typing import List\n",
        "\n",
        "class MultiLabelDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset: pd.DataFrame, split: str, list_of_labels: List[str] = None):\n",
        "\n",
        "        self.dataset = dataset\n",
        "        self.num_samples = len(self.dataset)\n",
        "\n",
        "        self.labels = list_of_labels\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "        self.encodings = tokenizer(\n",
        "            self.dataset[\"text\"].tolist(), truncation=True, padding=True\n",
        "        )\n",
        "        \n",
        "        # üî≠üåï Galileo logging\n",
        "        dq.log_data_samples(\n",
        "            texts=self.dataset[\"text\"],\n",
        "            task_labels=self.dataset[self.labels].apply(lambda row: list(row[row == 1].index.values), axis=1),\n",
        "            ids=self.dataset[\"id\"],\n",
        "            split=split,\n",
        "        )\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.tensor(self.encodings[\"input_ids\"][idx])\n",
        "        attention_mask = torch.tensor(self.encodings[\"attention_mask\"][idx])\n",
        "        y = torch.tensor(self.dataset[self.labels].iloc[idx])\n",
        "        return x, attention_mask, self.dataset['id'].iloc[idx], y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "# üî≠üåï Galileo logging\n",
        "dq.set_tasks_for_run(labels_cols, binary=True)\n",
        "\n",
        "train_dataset = MultiLabelDataset(\n",
        "    train_df, \n",
        "    split=\"training\", \n",
        "    list_of_labels = labels_cols, \n",
        ")\n",
        "\n",
        "test_dataset = MultiLabelDataset(\n",
        "    test_df, \n",
        "    split=\"validation\",\n",
        "    list_of_labels = labels_cols,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMV9XnJaSg9j"
      },
      "source": [
        "# 5. Log model data with Galileo\n",
        "\n",
        "Model data can be logged via `log_model_outputs`. This step will log the model logits and embeddings. You can achieve this by adding 1 line of code to the standard pytorch model. \n",
        "\n",
        "We log [CLS]-token embedding from final layer, but you can log any custom layer for embeddings. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kvfEg4cnzTZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear\n",
        "from transformers import AutoModel\n",
        "\n",
        "class TextMultiLabelClassificationModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, num_tasks):\n",
        "        super().__init__()\n",
        "        self.feature_extractor = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "        hidden_size = self.feature_extractor.config.hidden_size\n",
        "        \n",
        "        self.pre_classifier = torch.nn.Linear(hidden_size, hidden_size)\n",
        "        self.classifier = torch.nn.Linear(hidden_size, num_tasks)\n",
        "\n",
        "        self.dropout = torch.nn.Dropout(0.1)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "\n",
        "    def forward(self, x, attention_mask, ids):\n",
        "        \"\"\"Model forward function.\"\"\"\n",
        "        encoded_layers = self.feature_extractor(\n",
        "            input_ids=x, attention_mask=attention_mask\n",
        "        ).last_hidden_state\n",
        "        # Extract [CLS]-token\n",
        "        classification_embedding = encoded_layers[:, 0]\n",
        "\n",
        "        emb = self.pre_classifier(classification_embedding)\n",
        "        emb = self.relu(emb)\n",
        "        emb = self.dropout(emb)\n",
        "        logits = self.classifier(emb)\n",
        "\n",
        "        # üî≠üåï Galileo logging\n",
        "        dq.log_model_outputs(\n",
        "            embs=classification_embedding, logits=logits, ids=ids\n",
        "        )\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnEeJN1IyMl0"
      },
      "source": [
        "# 6. Putting into Action: Training a Model\n",
        "\n",
        "We complete the training pipeline by using a standard PyTorch training setup. While training, we log the current `epoch` and `split`. To complete logging, we call `dq.finish()` after training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lRIh9U7oL2V"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchmetrics\n",
        "from tqdm.notebook import tqdm\n",
        "from torchmetrics import HammingDistance\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, \n",
        "    batch_size=BATCH_SIZE, \n",
        "    shuffle=True,\n",
        ")\n",
        "val_dataloader = torch.utils.data.DataLoader(\n",
        "    test_dataset, \n",
        "    batch_size=BATCH_SIZE, \n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "model = TextMultiLabelClassificationModel(num_tasks=len(train_dataset.labels))\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5\n",
        ")\n",
        "\n",
        "train_acc = torchmetrics.Accuracy()\n",
        "val_acc = torchmetrics.Accuracy()\n",
        "\n",
        "train_hamming_distance = HammingDistance()\n",
        "val_hamming_distance = HammingDistance()\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    # üî≠üåï Galileo logging\n",
        "    dq.set_epoch(epoch)\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # üî≠üåï Galileo logging\n",
        "    dq.set_split(\"training\")\n",
        "    \n",
        "    for batch, data in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
        "        \n",
        "        x, attention_mask, x_idxs, y = data\n",
        "        x = x.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # forward + backward + optimize\n",
        "        logits = model(x, attention_mask, x_idxs)\n",
        "        loss = F.binary_cross_entropy_with_logits(logits, y.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    # Track batch level hamming loss!\n",
        "    train_hamming_distance(logits.to(\"cpu\"), y.to(\"cpu\"))\n",
        "    print(\"[epoch %d]\" % (epoch + 1))\n",
        "    print({'loss': running_loss / (batch + 1),\n",
        "                              \"hamming_score\": str(\n",
        "                                  \"%.3f\" % train_hamming_distance.compute())})\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # üî≠üåï Galileo logging\n",
        "        dq.set_split(\"validation\")\n",
        "\n",
        "        validation_loss = 0.0\n",
        "        for batch, data in enumerate(val_dataloader):\n",
        "            x, attention_mask, x_idxs, y = data\n",
        "\n",
        "            x = x.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            logits = model(x, attention_mask, x_idxs)\n",
        "            loss = F.binary_cross_entropy_with_logits(logits, y.float())\n",
        "\n",
        "            validation_loss += loss.item()\n",
        "            val_hamming_distance(logits.to(\"cpu\"), y.to(\"cpu\"))\n",
        "\n",
        "        print(\"[epoch %d] Validation loss: %.3f\" % (\n",
        "        epoch + 1, validation_loss / (batch + 1)))\n",
        "        print(f\"Val hamming score: {1 - val_hamming_distance.compute()}\")\n",
        "\n",
        "    train_hamming_distance.reset()\n",
        "    val_hamming_distance.reset()\n",
        "\n",
        "print(\"Finished Training\")\n",
        "\n",
        "# üî≠üåï Galileo logging\n",
        "dq.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkUoYnK0oFK_"
      },
      "source": [
        "# General Help and Docs\n",
        "- To get help with your task's requirements, call `dq.get_data_logger().doc()`\n",
        "- To see more general data and model logging docs, run `dq.docs()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "V9o7ZwZVZIiM"
      },
      "outputs": [],
      "source": [
        "dq.get_data_logger().doc()\n",
        "help(dq.log_dataset)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1IQ99tSgicpVpCrkhjTp-Dp_f2ucBhvy3",
          "timestamp": 1659469611341
        }
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.8 64-bit ('3.9.8')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "69676513e12c58fe5e31ac1dfc1388730f531acf91beac6a0891eeb2a01af125"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
