{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"shw_4MU8mLbR"},"source":["# 1. Install dependencies and download the data should take about 5 miutes"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qalu2lgvvJNu","outputId":"4e64f37c-03ad-46d4-e4df-6ee46f77f0c4"},"outputs":[{"name":"stderr","output_type":"stream","text":["Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/images/image_0.png...\n","/ [1 files][446.3 KiB/446.3 KiB]                                                \n","==> NOTE: You are performing a sequence of gsutil operations that may\n","run significantly faster if you instead use gsutil -m cp ... Please\n","see the -m section under \"gsutil help options\" for further information\n","about when gsutil -m can be advantageous.\n","\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/images/image_1.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/images/image_2.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/images/image_3.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/images/image_4.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/images/image_5.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/images/image_6.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/images/image_7.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/images/image_8.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/images/image_9.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/masks/mask_0.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/masks/mask_1.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/masks/mask_2.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/masks/mask_3.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/masks/mask_4.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/masks/mask_5.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/masks/mask_6.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/masks/mask_7.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/masks/mask_8.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/masks/mask_9.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/validation/images/image_10.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/validation/images/image_11.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/validation/images/image_12.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/validation/images/image_13.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/validation/images/image_14.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/validation/images/image_15.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/validation/masks/mask_10.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/validation/masks/mask_11.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/validation/masks/mask_12.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/validation/masks/mask_13.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/validation/masks/mask_14.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/validation/masks/mask_15.png...\n","\\ [32 files][  6.6 MiB/  6.6 MiB]                                               \n","==> NOTE: You are performing a sequence of gsutil operations that may\n","run significantly faster if you instead use gsutil -m cp ... Please\n","see the -m section under \"gsutil help options\" for further information\n","about when gsutil -m can be advantageous.\n","\n","\n","Operation completed over 32 objects/6.6 MiB.                                     \n"]}],"source":["!pip install -U datasets google-cloud-storage dataquality  &> /dev/null\n","import os\n","from tqdm import tqdm\n","from datasets import load_dataset\n","import torch \n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","import numpy as np\n","from matplotlib import pyplot as plt\n","from google.cloud import storage\n","\n","# download images\n","import os\n","os.system('gsutil cp -r \\\n","  \"gs://galileo-public-data/CV_datasets/Segmentation_Data\" \\\n","  . &> /dev/null')\n","\n","dataset_path = \"./Segmentation_Data\"\n","\n","IMG_SIZE = 256\n","NC = 21  # Number of classes"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"uikjPOjWvu8Q"},"source":["# 2. Create the dataset class\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"tZS9o7-2qFoA"},"outputs":[],"source":["from typing import Optional, Dict, Union\n","from PIL import Image\n","\n","class coco_hf_dataset_disk(torch.utils.data.Dataset):\n","    def __init__(self, \n","                 dataset_path: str,\n","                 relative_img_path: str, \n","                 relative_mask_path: str,\n","                 mask_transform: transforms=None, \n","                 img_transform: transforms=None, \n","                 size: int=1024,) -> None:\n","        \"\"\"\"\n","        COCO val dataset from galileo-public-data/CV_datasets/COCO_seg_val_5000/all_images\n","        downloaded and located on disk.\n","        If no paths are provided we download the dataset from GCS and save it to disk.\n","\n","        :param dataset_path: path to dataset\n","        :param relative_img_path: path to images relative to the dataset path\n","        :param relative_maks_path: path to masks relative to the dataset path\n","        :param mask_transform: transforms to apply to masks\n","        :param img_transform: transforms to apply to images\n","        :param size: size of image and mask\n","        \"\"\"\n","        super(coco_hf_dataset_disk, self).__init__()\n","\n","        self.dataset_path = dataset_path\n","        self.relative_img_path = relative_img_path\n","        self.relative_mask_path = relative_mask_path\n","        self.images = sorted(os.listdir(os.path.join(dataset_path, relative_img_path)))\n","        self.masks = sorted(os.listdir(os.path.join(dataset_path, relative_mask_path)))\n","        # remove .DS_Store\n","        if self.images[0] == '.DS_Store':\n","            self.images = self.images[1:]\n","        if self.masks[0] == '.DS_Store':\n","            self.masks = self.masks[1:]\n","\n","        num_images = len(self.images)\n","        num_masks = len(self.masks)\n","        print(f\"Found dataset, there are {num_images} images and {num_masks} masks\")\n","\n","        self.mask_transform = mask_transform\n","        self.img_transform = img_transform\n","\n","        self.class_dict = { 'background': 0, 'airplane': 1, 'bicycle': 2,\n","                            'bird': 3, 'boat': 4, 'bottle': 5, 'bus': 6,\n","                            'car': 7, 'cat': 8, 'chair': 9, 'cow': 10,\n","                            'dining table': 11,'dog': 12,'horse': 13,\n","                            'motorcycle': 14,'person': 15,'potted plant': 16,\n","                            'sheep': 17, 'couch': 18, 'train': 19, 'tv': 20}\n","        self.labels = [i for i in self.class_dict]\n","                        \n","        self.int2str = {v: k for k, v in self.class_dict.items()}\n","        self.size = size\n","\n","    def __len__(self) -> int:\n","        # returns length of the dataset\n","        return len(self.images)\n","\n","    def __getitem__(self, idx: int) -> Dict[str, Union[torch.Tensor, int, np.ndarray]]:\n","        # gets a single item from our dataset\n","        \n","        image_path = os.path.join(self.dataset_path, self.relative_img_path, self.images[idx])\n","        mask_path = os.path.join(self.dataset_path, self.relative_mask_path, self.masks[idx])\n","        image = Image.open(image_path)\n","        mask = Image.open(mask_path)\n","\n","        # resize image and mask to given size\n","        unnormalized_image = image.copy().resize((self.size, self.size), resample=Image.NEAREST)\n","        unnormalized_image = transforms.ToTensor()(unnormalized_image)\n","        unnormalized_image = expand_gray_channel()(unnormalized_image)\n","        unnormalized_image = np.array(unnormalized_image)\n","        \n","\n","        if self.img_transform:\n","            image = self.img_transform(image)\n","        if self.mask_transform:\n","            mask = self.mask_transform(mask)\n","        \n","        return {'image': image,\n","                'image_path': image_path,\n","                'mask_path': mask_path,\n","                'mask': mask,\n","                'idx': idx,\n","                'unnormalized_image': unnormalized_image}\n","\n","\n","class expand_gray_channel:\n","    def __call__(self, tensor: torch.Tensor) -> torch.Tensor:\n","        # torch transform to expand gray channel to 3 channels\n","        if tensor.shape[0] > 3:\n","            tensor = tensor.unsqueeze(0)\n","        if tensor.shape[0] == 1:\n","            return tensor.expand(3, -1, -1)\n","        return tensor\n","    "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ALIZoeAKyQlj"},"source":["# 3. Create the datasets, dataloaders, model and optimizer"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"z2sdPZFjyO7B"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found dataset, there are 10 images and 10 masks\n","Found dataset, there are 6 images and 6 masks\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /Users/derek/.cache/torch/hub/pytorch_vision_v0.10.0\n","/Users/derek/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/Users/derek/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}],"source":["img_transforms = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Resize((IMG_SIZE, IMG_SIZE), interpolation=transforms.InterpolationMode.BICUBIC),\n","    expand_gray_channel(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","mask_transforms = transforms.Compose([\n","    transforms.PILToTensor(),\n","    transforms.Resize((IMG_SIZE, IMG_SIZE), interpolation=transforms.InterpolationMode.NEAREST),\n","])\n","\n","train_image_path = 'train/images'\n","train_mask_path = 'train/masks'\n","validation_image_path = 'validation/images'\n","validation_mask_path = 'validation/masks'\n","\n","train_dataset = coco_hf_dataset_disk(dataset_path=dataset_path,\n","                                    relative_img_path=train_image_path, \n","                                    relative_mask_path=train_mask_path,\n","                                    img_transform=img_transforms,\n","                                     mask_transform=mask_transforms,\n","                                    size=IMG_SIZE)\n","validation_dataset = coco_hf_dataset_disk(dataset_path=dataset_path,\n","                                    relative_img_path=validation_image_path, \n","                                    relative_mask_path=validation_mask_path,\n","                                    img_transform=img_transforms,\n","                                     mask_transform=mask_transforms,\n","                                    size=IMG_SIZE)\n","labels = train_dataset.labels\n","train_dataloader = DataLoader(train_dataset, batch_size = 6, shuffle=True, num_workers=4)\n","validation_dataloader = DataLoader(validation_dataset, batch_size = 6, shuffle=True, num_workers=4)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', pretrained=True).to(device)\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr = .00001)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"y7jC3C-K0F2b"},"source":["# 4. Train with Dataquality  🔭"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"G06JZVz_0E7v"},"outputs":[{"name":"stdout","output_type":"stream","text":["Welcome to Galileo Cloud v0.8.45!\n"]},{"name":"stderr","output_type":"stream","text":["2023-05-31 13:55:35.245593: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","/Users/derek/opt/anaconda3/lib/python3.9/site-packages/dataquality/core/__init__.py:27: GalileoWarning: configure is deprecated, use dq.set_console_url and dq.login\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Welcome to Galileo v0.8.45!\n","To skip this prompt in the future, set the following environment variable: GALILEO_CONSOLE_URL\n","📡 https://console.cloud.rungalileo.io\n","🔭 Logging you into Galileo\n","\n","Go to https://console.cloud.rungalileo.io/get-token to generate a new API Key\n","🚀 You're logged in to Galileo as derek@rungalileo.io!\n","✨ Initializing new public project 'Segmentation_Project'\n","🏃‍♂️ Creating new run 'COCO_dataset'\n","🛰 Connected to new project 'Segmentation_Project', and new run 'COCO_dataset'.\n","We assume the dataloaders passed only have transforms that Tensor, Resize,         and Normalize the image and mask\n","‼ Any cropping or shearing transforms passed will lead to unexpected         results\n","See docs at https://dq.readthedocs.io/en/latest/ (placeholder) for more info         \n"," \n","\n","Found layer \"classifier\" in model layers: \"backbone, classifier\"\n"]},{"name":"stderr","output_type":"stream","text":["/var/folders/hm/ll4g2nzj0jnckzf_w02pc2lm0000gn/T/ipykernel_5397/1713176154.py:68: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n","  unnormalized_image = image.copy().resize((self.size, self.size), resample=Image.NEAREST)\n"]}],"source":["import dataquality as dq\n","from dataquality.integrations.cv.torch.semantic_segmentation import watch\n","\n","# set to avoid being prompted for credentials\n","# %env GALILEO_CONSOLE_URL = \"https://console.cloud.rungalileo.io/\" \n","# %env GALILEO_USERNAME = \n","# %env GALILEO_PASSWORD = \n","\n","# dq.configure()\n","dq.init(\"semantic_segmentation\", \"Segmentation_Project\", 'COCO_dataset')\n","\n","watch(\n","    model,\n","    bucket_url='https://storage.googleapis.com/galileo-public-data/CV_datasets/COCO_segmentation_example_data',\n","    dataset_path=dataset_path,\n","    dataloaders={\"training\": train_dataloader,\n","                 \"validation\": validation_dataloader},\n",")\n","dq.set_labels_for_run(labels)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"40ca8s8tXmtL"},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/derek/opt/anaconda3/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n","  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n","/Users/derek/opt/anaconda3/lib/python3.9/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n","  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n","  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/hm/ll4g2nzj0jnckzf_w02pc2lm0000gn/T/ipykernel_5397/1713176154.py:68: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n","  unnormalized_image = image.copy().resize((self.size, self.size), resample=Image.NEAREST)\n","100%|██████████| 2/2 [00:12<00:00,  6.29s/it]\n"]}],"source":["# train for one epoch\n","\n","scaler = torch.cuda.amp.GradScaler()\n","epochs = 1\n","\n","with torch.autocast('cuda'):\n","    for epoch in range(epochs):\n","        dq.set_epoch_and_split(epoch, \"training\")\n","        for j, sample in enumerate(tqdm(train_dataloader)):\n","            imgs, masks = sample['image'], sample['mask']\n","            out = model(imgs.to(device))\n","\n","            # reshape to have loss for each pixel (bs * h * w, 21)\\n\",\n","            pred = out['out'].permute(0, 2, 3, 1).contiguous().view( -1, 21)\n","            masks = masks.long()\n","            msks_for_loss = masks.view(-1).to(device)\n","\n","            loss = criterion(pred, msks_for_loss)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"background_save":true},"id":"CAqZVAbiXryu"},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/hm/ll4g2nzj0jnckzf_w02pc2lm0000gn/T/ipykernel_5397/1713176154.py:68: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n","  unnormalized_image = image.copy().resize((self.size, self.size), resample=Image.NEAREST)\n","/Users/derek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/08bc20f4f895f3caf75fb9e3fada1404bded3c3265243d05327cbb3b9326ffe9/mean_iou.py:259: RuntimeWarning: invalid value encountered in divide\n","  iou = total_area_intersect / total_area_union\n","/Users/derek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/08bc20f4f895f3caf75fb9e3fada1404bded3c3265243d05327cbb3b9326ffe9/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n","  acc = total_area_intersect / total_area_label\n"]},{"name":"stdout","output_type":"stream","text":["Logging 4 samples [########################################] 100.00% elapsed time  :     0.29s =  0.0m =  0.0h\n","Logging 6 samples [########################################] 100.00% elapsed time  :     0.18s =  0.0m =  0.0h\n","Logging 6 samples [########################################] 100.00% elapsed time  :     0.18s =  0.0m =  0.0h\n"," ☁️ Uploading Data\n","CuML libraries not found, running standard process. For faster Galileo processing, consider installing\n","`pip install 'dataquality[cuda]' --extra-index-url=https://pypi.nvidia.com/`\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"24060a321f2c45ebb9ca5686038f4a12","version_major":2,"version_minor":0},"text/plain":["Uploading data to Galileo:   0%|          | 0.00/32.3k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5d6e2a5ae527463bbfe648c042dac383","version_major":2,"version_minor":0},"text/plain":["Processing data for upload:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5b8c8964131f43bea85e9e0f88055719","version_major":2,"version_minor":0},"text/plain":["Uploading data to Galileo:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"25e733243f9f4898905ed7e372da0172","version_major":2,"version_minor":0},"text/plain":["Uploading data to Galileo:   0%|          | 0.00/30.3k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"632d973053744754a98c26b551583771","version_major":2,"version_minor":0},"text/plain":["Processing data for upload:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d0e1f6b3e51a4dfa8e54cca393fbdf39","version_major":2,"version_minor":0},"text/plain":["Uploading data to Galileo:   0%|          | 0.00/34.7k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/31/23 13:57:04] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> could not close memmap for column                                   <a href=\"file:///Users/derek/opt/anaconda3/lib/python3.9/site-packages/vaex/dataset_mmap.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">dataset_mmap.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/derek/opt/anaconda3/lib/python3.9/site-packages/vaex/dataset_mmap.py#94\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">94</span></a>\n","<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/Users/derek/.galileo/logs/f0de2cdc-5940-4997-ab3c-c354e0120823/a93</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                  </span>\n","<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080\">acda7-8964-4d34-82fa-bdac4d91c372/input_data/validation/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">data_0.hdf5</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                  </span>\n","</pre>\n"],"text/plain":["\u001b[2;36m[05/31/23 13:57:04]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m could not close memmap for column                                   \u001b]8;id=335036;file:///Users/derek/opt/anaconda3/lib/python3.9/site-packages/vaex/dataset_mmap.py\u001b\\\u001b[2mdataset_mmap.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=461726;file:///Users/derek/opt/anaconda3/lib/python3.9/site-packages/vaex/dataset_mmap.py#94\u001b\\\u001b[2m94\u001b[0m\u001b]8;;\u001b\\\n","\u001b[2;36m                    \u001b[0m         \u001b[35m/Users/derek/.galileo/logs/f0de2cdc-5940-4997-ab3c-c354e0120823/a93\u001b[0m \u001b[2m                  \u001b[0m\n","\u001b[2;36m                    \u001b[0m         \u001b[35macda7-8964-4d34-82fa-bdac4d91c372/input_data/validation/\u001b[0m\u001b[95mdata_0.hdf5\u001b[0m \u001b[2m                  \u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Job default successfully submitted. Results will be available soon at https://console.cloud.rungalileo.io/insights?projectId=f0de2cdc-5940-4997-ab3c-c354e0120823&runId=a93acda7-8964-4d34-82fa-bdac4d91c372&split=training&metric=f1&depHigh=1&depLow=0&taskType=6\n","Waiting for job (you can safely close this window)...\n","\t[training] 👀 Looking for data anomalies\n","\t[validation] 👀 Looking for data anomalies\n","Done! Job finished with status completed\n","Click here to see your run! https://console.cloud.rungalileo.io/insights?projectId=f0de2cdc-5940-4997-ab3c-c354e0120823&runId=a93acda7-8964-4d34-82fa-bdac4d91c372&split=training&metric=f1&depHigh=1&depLow=0&taskType=6\n","🧹 Cleaning up\n","🧹 Cleaning up\n"]},{"data":{"text/plain":["'https://console.cloud.rungalileo.io/insights?projectId=f0de2cdc-5940-4997-ab3c-c354e0120823&runId=a93acda7-8964-4d34-82fa-bdac4d91c372&split=training&metric=f1&depHigh=1&depLow=0&taskType=6'"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["dq.finish()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPjTFUR776gZDthnyhxh+8R","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
