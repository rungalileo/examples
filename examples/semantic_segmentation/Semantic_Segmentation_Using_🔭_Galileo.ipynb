{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"shw_4MU8mLbR"},"source":["# 1. Install dependencies and download the data should take about 5 miutes"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qalu2lgvvJNu","outputId":"4e64f37c-03ad-46d4-e4df-6ee46f77f0c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/images/image_0.png...\n","/ [1 files][446.3 KiB/446.3 KiB]                                                \n","==> NOTE: You are performing a sequence of gsutil operations that may\n","run significantly faster if you instead use gsutil -m cp ... Please\n","see the -m section under \"gsutil help options\" for further information\n","about when gsutil -m can be advantageous.\n","\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/images/image_1.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/images/image_2.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/images/image_3.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/images/image_4.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/images/image_5.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/images/image_6.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/images/image_7.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/images/image_8.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/images/image_9.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/masks/mask_0.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/masks/mask_1.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/masks/mask_2.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/masks/mask_3.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/masks/mask_4.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/masks/mask_5.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/masks/mask_6.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/masks/mask_7.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/masks/mask_8.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/train/masks/mask_9.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/validation/images/image_10.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/validation/images/image_11.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/validation/images/image_12.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/validation/images/image_13.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/validation/images/image_14.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/validation/images/image_15.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/validation/masks/mask_10.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/validation/masks/mask_11.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/validation/masks/mask_12.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/validation/masks/mask_13.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/validation/masks/mask_14.png...\n","Copying gs://galileo-public-data/CV_datasets/Segmentation_Data/validation/masks/mask_15.png...\n","/ [32 files][  6.6 MiB/  6.6 MiB]                                               \n","==> NOTE: You are performing a sequence of gsutil operations that may\n","run significantly faster if you instead use gsutil -m cp ... Please\n","see the -m section under \"gsutil help options\" for further information\n","about when gsutil -m can be advantageous.\n","\n","\n","Operation completed over 32 objects/6.6 MiB.                                     \n"]}],"source":["!pip install -U dataquality  &> /dev/null\n","import os\n","os.mkdir('Datasets')\n","!gsutil cp -r gs://galileo-public-data/CV_datasets/Segmentation_Data Datasets\n","from tqdm import tqdm\n","import torch \n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","import numpy as np\n","import os\n","\n","\n","dataset_path = os.path.abspath(\"Datasets/Segmentation_Data\")\n","\n","IMG_SIZE = 256\n","NC = 21  # Number of classes"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"uikjPOjWvu8Q"},"source":["# 2. Create the dataset class\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"tZS9o7-2qFoA"},"outputs":[],"source":["from typing import Optional, Dict, Union\n","from PIL import Image\n","\n","class coco_hf_dataset_disk(torch.utils.data.Dataset):\n","    def __init__(self, \n","                 dataset_path: str,\n","                 relative_img_path: str, \n","                 relative_mask_path: str,\n","                 mask_transform: transforms=None, \n","                 img_transform: transforms=None, \n","                 size: int=1024,) -> None:\n","        \"\"\"\"\n","        COCO val dataset from galileo-public-data/CV_datasets/COCO_seg_val_5000/all_images\n","        downloaded and located on disk.\n","        If no paths are provided we download the dataset from GCS and save it to disk.\n","\n","        :param dataset_path: path to dataset\n","        :param relative_img_path: path to images relative to the dataset path\n","        :param relative_maks_path: path to masks relative to the dataset path\n","        :param mask_transform: transforms to apply to masks\n","        :param img_transform: transforms to apply to images\n","        :param size: size of image and mask\n","        \"\"\"\n","        super(coco_hf_dataset_disk, self).__init__()\n","\n","        self.dataset_path = dataset_path\n","        self.relative_img_path = relative_img_path\n","        self.relative_mask_path = relative_mask_path\n","        self.images = sorted(os.listdir(os.path.join(dataset_path, relative_img_path)))\n","        self.masks = sorted(os.listdir(os.path.join(dataset_path, relative_mask_path)))\n","        # remove .DS_Store\n","        if self.images[0] == '.DS_Store':\n","            self.images = self.images[1:]\n","        if self.masks[0] == '.DS_Store':\n","            self.masks = self.masks[1:]\n","\n","        num_images = len(self.images)\n","        num_masks = len(self.masks)\n","        print(f\"Found dataset, there are {num_images} images and {num_masks} masks\")\n","\n","        self.mask_transform = mask_transform\n","        self.img_transform = img_transform\n","\n","        self.class_dict = { 'background': 0, 'airplane': 1, 'bicycle': 2,\n","                            'bird': 3, 'boat': 4, 'bottle': 5, 'bus': 6,\n","                            'car': 7, 'cat': 8, 'chair': 9, 'cow': 10,\n","                            'dining table': 11,'dog': 12,'horse': 13,\n","                            'motorcycle': 14,'person': 15,'potted plant': 16,\n","                            'sheep': 17, 'couch': 18, 'train': 19, 'tv': 20}\n","        self.labels = [i for i in self.class_dict]\n","                        \n","        self.int2str = {v: k for k, v in self.class_dict.items()}\n","        self.size = size\n","\n","    def __len__(self) -> int:\n","        # returns length of the dataset\n","        return len(self.images)\n","\n","    def __getitem__(self, idx: int) -> Dict[str, Union[torch.Tensor, int, np.ndarray]]:\n","        # gets a single item from our dataset\n","        \n","        image_path = os.path.join(self.dataset_path, self.relative_img_path, self.images[idx])\n","        mask_path = os.path.join(self.dataset_path, self.relative_mask_path, self.masks[idx])\n","        image = Image.open(image_path)\n","        mask = Image.open(mask_path)\n","\n","        # resize image and mask to given size\n","        unnormalized_image = image.copy().resize((self.size, self.size), resample=Image.NEAREST)\n","        unnormalized_image = transforms.ToTensor()(unnormalized_image)\n","        unnormalized_image = expand_gray_channel()(unnormalized_image)\n","        unnormalized_image = np.array(unnormalized_image)\n","        \n","\n","        if self.img_transform:\n","            image = self.img_transform(image)\n","        if self.mask_transform:\n","            mask = self.mask_transform(mask)\n","        \n","        return {'image': image,\n","                'image_path': image_path,\n","                'mask_path': mask_path,\n","                'mask': mask,\n","                'idx': idx,\n","                'unnormalized_image': unnormalized_image}\n","\n","\n","class expand_gray_channel:\n","    def __call__(self, tensor: torch.Tensor) -> torch.Tensor:\n","        # torch transform to expand gray channel to 3 channels\n","        if tensor.shape[0] > 3:\n","            tensor = tensor.unsqueeze(0)\n","        if tensor.shape[0] == 1:\n","            return tensor.expand(3, -1, -1)\n","        return tensor\n","    "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ALIZoeAKyQlj"},"source":["# 3. Create the datasets, dataloaders, model and optimizer"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"z2sdPZFjyO7B"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found dataset, there are 10 images and 10 masks\n","Found dataset, there are 6 images and 6 masks\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /Users/derek/.cache/torch/hub/pytorch_vision_v0.10.0\n","/Users/derek/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/Users/derek/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}],"source":["img_transforms = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Resize((IMG_SIZE, IMG_SIZE), interpolation=transforms.InterpolationMode.BICUBIC),\n","    expand_gray_channel(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","mask_transforms = transforms.Compose([\n","    transforms.PILToTensor(),\n","    transforms.Resize((IMG_SIZE, IMG_SIZE), interpolation=transforms.InterpolationMode.NEAREST),\n","])\n","\n","train_image_path = 'train/images'\n","train_mask_path = 'train/masks'\n","validation_image_path = 'validation/images'\n","validation_mask_path = 'validation/masks'\n","\n","train_dataset = coco_hf_dataset_disk(dataset_path=dataset_path,\n","                                    relative_img_path=train_image_path, \n","                                    relative_mask_path=train_mask_path,\n","                                    img_transform=img_transforms,\n","                                     mask_transform=mask_transforms,\n","                                    size=IMG_SIZE)\n","validation_dataset = coco_hf_dataset_disk(dataset_path=dataset_path,\n","                                    relative_img_path=validation_image_path, \n","                                    relative_mask_path=validation_mask_path,\n","                                    img_transform=img_transforms,\n","                                     mask_transform=mask_transforms,\n","                                    size=IMG_SIZE)\n","labels = train_dataset.labels\n","train_dataloader = DataLoader(train_dataset, batch_size = 6, shuffle=True, num_workers=4)\n","validation_dataloader = DataLoader(validation_dataset, batch_size = 6, shuffle=True, num_workers=4)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', pretrained=True).to(device)\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr = .00001)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"y7jC3C-K0F2b"},"source":["# 4. Train with Dataquality  üî≠"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"G06JZVz_0E7v"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-06-15 11:27:39.906841: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]},{"name":"stdout","output_type":"stream","text":["‚ú® Initializing existing public project 'Segmentation_Project'\n","üèÉ‚Äç‚ôÇÔ∏è Fetching existing run 'COCO_dataset'\n"]},{"name":"stderr","output_type":"stream","text":["/Users/derek/opt/anaconda3/lib/python3.9/site-packages/dataquality/core/init.py:207: GalileoWarning: Run: Segmentation_Project/COCO_dataset already exists! The existing run will get overwritten on call to finish()!\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["üõ∞ Connected to existing project 'Segmentation_Project', and existing run 'COCO_dataset'.\n","üöÄ Found existing run labels. Setting labels for run to ['background', 'airplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'dining table', 'dog', 'horse', 'motorcycle', 'person', 'potted plant', 'sheep', 'couch', 'train', 'tv']. You do not need to set labels for this run.\n","We assume the dataloaders passed only have transforms that Tensor, Resize and Normalize the image and mask\n","Any cropping or shearing transforms passed will lead to unexpected results\n","See docs at https://docs.rungalileo.io/galileo/how-to-and-faq/python-sdk/watch for more info\n","Found layer \"classifier\" in model layers: \"backbone, classifier\"\n"]},{"name":"stderr","output_type":"stream","text":["/var/folders/hm/ll4g2nzj0jnckzf_w02pc2lm0000gn/T/ipykernel_3188/1713176154.py:68: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n","  unnormalized_image = image.copy().resize((self.size, self.size), resample=Image.NEAREST)\n"]}],"source":["import dataquality as dq\n","from dataquality.integrations.torch_semantic_segmentation import watch\n","\n","# set to avoid being prompted for credentials\n","# %env GALILEO_CONSOLE_URL = \"https://console.cloud.rungalileo.io/\" \n","# %env GALILEO_USERNAME = \n","# %env GALILEO_PASSWORD = \n","\n","# dq.configure()\n","dq.init(\"semantic_segmentation\", \"Segmentation_Project\", 'COCO_dataset')\n","\n","watch(\n","    model,\n","    imgs_remote_location='gs://galileo-public-data/CV_datasets/Segmentation_Data',\n","    local_path_to_dataset_root=dataset_path,\n","    dataloaders={\"training\": train_dataloader,\n","                 \"validation\": validation_dataloader},\n",")\n","dq.set_labels_for_run(labels)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"40ca8s8tXmtL"},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/derek/opt/anaconda3/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n","  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n","/Users/derek/opt/anaconda3/lib/python3.9/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n","  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n","  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/hm/ll4g2nzj0jnckzf_w02pc2lm0000gn/T/ipykernel_3188/1713176154.py:68: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n","  unnormalized_image = image.copy().resize((self.size, self.size), resample=Image.NEAREST)\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:12<00:00,  6.06s/it]\n"]}],"source":["# train for one epoch\n","\n","scaler = torch.cuda.amp.GradScaler()\n","epochs = 1\n","\n","with torch.autocast('cuda'):\n","    for epoch in range(epochs):\n","        dq.set_epoch_and_split(epoch, \"training\")\n","        for j, sample in enumerate(tqdm(train_dataloader)):\n","            imgs, masks = sample['image'], sample['mask']\n","            out = model(imgs.to(device))\n","\n","            # reshape to have loss for each pixel (bs * h * w, 21)\\n\",\n","            pred = out['out'].permute(0, 2, 3, 1).contiguous().view( -1, 21)\n","            masks = masks.long()\n","            msks_for_loss = masks.view(-1).to(device)\n","\n","            loss = criterion(pred, msks_for_loss)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"background_save":true},"id":"CAqZVAbiXryu"},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/hm/ll4g2nzj0jnckzf_w02pc2lm0000gn/T/ipykernel_3188/1713176154.py:68: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n","  unnormalized_image = image.copy().resize((self.size, self.size), resample=Image.NEAREST)\n","/Users/derek/opt/anaconda3/lib/python3.9/site-packages/dataquality/utils/semantic_segmentation/metrics.py:249: RuntimeWarning: invalid value encountered in divide\n","  iou_per_class = intersection_pixels / union_pixels_per_class\n"]},{"name":"stdout","output_type":"stream","text":["Logging 6 samples [########################################] 100.00% elapsed time  :     0.36s =  0.0m =  0.0h\n","Logging 4 samples [########################################] 100.00% elapsed time  :     0.15s =  0.0m =  0.0h\n","Logging 6 samples [########################################] 100.00% elapsed time  :     0.16s =  0.0m =  0.0h\n"," ‚òÅÔ∏è Uploading Data\n","CuML libraries not found, running standard process. For faster Galileo processing, consider installing\n","`pip install 'dataquality[cuda]' --extra-index-url=https://pypi.nvidia.com/`\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f1e7aed3f55f4427b335c6271b2b343c","version_major":2,"version_minor":0},"text/plain":["Uploading data to Galileo:   0%|          | 0.00/32.3k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4215c67580ef43e3b81478502a7da775","version_major":2,"version_minor":0},"text/plain":["Processing data for upload:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9434b9d7d87b4a32a57087a275532ffe","version_major":2,"version_minor":0},"text/plain":["Uploading data to Galileo:   0%|          | 0.00/39.2k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3da6b60891cd433893b2aaf6509b6e77","version_major":2,"version_minor":0},"text/plain":["Uploading data to Galileo:   0%|          | 0.00/30.3k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2b4b9138964940d289e5fa35e2954923","version_major":2,"version_minor":0},"text/plain":["Processing data for upload:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"27000cdc99a440cdb371b496c56dfb06","version_major":2,"version_minor":0},"text/plain":["Uploading data to Galileo:   0%|          | 0.00/34.7k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[06/15/23 11:28:24] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> could not close memmap for column                                   <a href=\"file:///Users/derek/opt/anaconda3/lib/python3.9/site-packages/vaex/dataset_mmap.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">dataset_mmap.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/derek/opt/anaconda3/lib/python3.9/site-packages/vaex/dataset_mmap.py#94\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">94</span></a>\n","<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/Users/derek/.galileo/logs/c7d3ceca-5fb9-4ff9-b085-b9a6d3299d35/f16</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                  </span>\n","<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080\">c2d4f-5d73-43e7-bb81-3a3ac91f03ee/input_data/validation/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">data_0.hdf5</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                  </span>\n","</pre>\n"],"text/plain":["\u001b[2;36m[06/15/23 11:28:24]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m could not close memmap for column                                   \u001b]8;id=725339;file:///Users/derek/opt/anaconda3/lib/python3.9/site-packages/vaex/dataset_mmap.py\u001b\\\u001b[2mdataset_mmap.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=279325;file:///Users/derek/opt/anaconda3/lib/python3.9/site-packages/vaex/dataset_mmap.py#94\u001b\\\u001b[2m94\u001b[0m\u001b]8;;\u001b\\\n","\u001b[2;36m                    \u001b[0m         \u001b[35m/Users/derek/.galileo/logs/c7d3ceca-5fb9-4ff9-b085-b9a6d3299d35/f16\u001b[0m \u001b[2m                  \u001b[0m\n","\u001b[2;36m                    \u001b[0m         \u001b[35mc2d4f-5d73-43e7-bb81-3a3ac91f03ee/input_data/validation/\u001b[0m\u001b[95mdata_0.hdf5\u001b[0m \u001b[2m                  \u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Job default successfully submitted. Results will be available soon at https://console.dev.rungalileo.io/insights?projectId=c7d3ceca-5fb9-4ff9-b085-b9a6d3299d35&runId=f16c2d4f-5d73-43e7-bb81-3a3ac91f03ee&taskType=6&split=training\n","Waiting for job (you can safely close this window)...\n","\tSaving processed validation data\n","Done! Job finished with status completed\n","Click here to see your run! https://console.dev.rungalileo.io/insights?projectId=c7d3ceca-5fb9-4ff9-b085-b9a6d3299d35&runId=f16c2d4f-5d73-43e7-bb81-3a3ac91f03ee&taskType=6&split=training\n","üßπ Cleaning up\n","üßπ Cleaning up\n"]},{"data":{"text/plain":["'https://console.dev.rungalileo.io/insights?projectId=c7d3ceca-5fb9-4ff9-b085-b9a6d3299d35&runId=f16c2d4f-5d73-43e7-bb81-3a3ac91f03ee&taskType=6&split=training'"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["dq.finish()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPjTFUR776gZDthnyhxh+8R","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
