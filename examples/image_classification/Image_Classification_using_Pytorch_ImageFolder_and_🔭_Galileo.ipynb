{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fccf6556",
      "metadata": {
        "id": "fccf6556"
      },
      "source": [
        "# Image Classification using PyTorch and ðŸ”­ Galileo\n",
        "\n",
        "In this tutorial, we'll train a model with PyTorch and explore the results in Galileo.\n",
        "\n",
        "This notebook pulls data from S3 and is the suggested way for working with images in Galileo.\n",
        "\n",
        "**Make sure to select GPU in your Runtime! (Runtime -> Change Runtime type)**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NkLn5MRHbowm",
      "metadata": {
        "id": "NkLn5MRHbowm"
      },
      "source": [
        "# 1. Install Prerequisites and Login Galileo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vthATGXfFAup",
      "metadata": {
        "cellView": "form",
        "id": "vthATGXfFAup"
      },
      "outputs": [],
      "source": [
        "#@markdown Install `dataquality`\n",
        "# Upgrade pip\n",
        "!pip install -U pip &> /dev/null\n",
        "\n",
        "# Install all dependecies\n",
        "!pip install -U dataquality &> /dev/null\n",
        "\n",
        "print('ðŸ‘‹ Installed necessary libraries!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zBGmxapS_S5w",
      "metadata": {
        "cellView": "form",
        "id": "zBGmxapS_S5w"
      },
      "outputs": [],
      "source": [
        "#@markdown Check that a GPU is available\n",
        "\n",
        "import torch\n",
        "# Check Cuda.\n",
        "if torch.cuda.is_available():\n",
        "  print(\"âš¡ You are connected to a GPU!\")\n",
        "else:\n",
        "  print(\"â—You are NOT connected to a GPU â—It is recommended to connect to a GPU before training\")\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bi3jMDTScRIB",
      "metadata": {
        "id": "bi3jMDTScRIB"
      },
      "outputs": [],
      "source": [
        "import dataquality as dq\n",
        "\n",
        "dq.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ty4TmPT7TYTO",
      "metadata": {
        "id": "Ty4TmPT7TYTO"
      },
      "source": [
        "# 2. Download the data in the notebook\n",
        "\n",
        "Pull the data from GCS or S3. \n",
        "\n",
        "For enterprise customers, your cluster will have to have permissions to request data from S3 and GCS for AWS and GCP clusters. Cross account transfer is not currently supported.\n",
        "\n",
        "For free users, the data has to be publicly available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8qH3-LXTh9Z",
      "metadata": {
        "id": "f8qH3-LXTh9Z"
      },
      "outputs": [],
      "source": [
        "CLOUD_ZIP_PATH = f\"https://storage.googleapis.com/galileo-public-data/CV_datasets/ImageNet10_animals_train_val.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WShoKNhsTh5Z",
      "metadata": {
        "cellView": "form",
        "id": "WShoKNhsTh5Z"
      },
      "outputs": [],
      "source": [
        "#@markdown Download the images\n",
        "\n",
        "LOCAL_DATA_DIR = \"dataset\"\n",
        "dataset_dir_name = CLOUD_ZIP_PATH.split('/')[-1].split('.zip')[0]\n",
        "\n",
        "cmd = f\"\"\"\n",
        "mkdir -p {LOCAL_DATA_DIR}\n",
        "if [ ! -d {LOCAL_DATA_DIR}/{dataset_dir_name} ]\n",
        "then\n",
        "  echo \"Downloading data\"\n",
        "  curl {CLOUD_ZIP_PATH} -o {LOCAL_DATA_DIR}/{dataset_dir_name}.zip\n",
        "  unzip {LOCAL_DATA_DIR}/{dataset_dir_name}.zip -d {LOCAL_DATA_DIR}\n",
        "else\n",
        "  echo \"Data already exists locally. Moving on.\"\n",
        "fi\n",
        "\"\"\"\n",
        "with open('download_images.sh', 'w') as file:\n",
        "  file.write(cmd)\n",
        "\n",
        "!bash download_images.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vQI6GwGGcFIE",
      "metadata": {
        "id": "vQI6GwGGcFIE"
      },
      "source": [
        "# 3. Initialize Galileo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oXua2j7QFFBJ",
      "metadata": {
        "id": "oXua2j7QFFBJ"
      },
      "outputs": [],
      "source": [
        "# ðŸ”­ðŸŒ• DATASET_NAME is only used for creating a run name in Galileo\n",
        "DATASET_NAME = \"ImageNet10_animals_train_val\" \n",
        "\n",
        "# ðŸ”­ðŸŒ• Initializing a new run in Galileo. Each run is part of a project.\n",
        "dq.init(task_type=\"image_classification\", \n",
        "        project_name=\"image_classification_pytorch\", \n",
        "        run_name=f\"example_run_{DATASET_NAME.replace('/', '-')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "etbtUHJyGwyD",
      "metadata": {
        "id": "etbtUHJyGwyD"
      },
      "source": [
        "# 4. Create Dataset and Log Input Data with Galileo\n",
        "\n",
        "Input data is logged via `log_image_dataset`. This step will log the images, gold labels, data split, and list of all labels. You can achieve by simply calling the method in 1 line of code, see below.\n",
        "\n",
        "To skip uploading the images, provide their location in the variable `imgs_remote_location`. Note that the images have to be in an (unzipped) folder in the cloud, and the folder structure has to be the same as the local folder structure (in this notebook)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NstRss_nWaPH",
      "metadata": {
        "cellView": "form",
        "id": "NstRss_nWaPH"
      },
      "outputs": [],
      "source": [
        "#@markdown Fix a random Seed and load helper methods.\n",
        "from typing import Optional, List\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Fix a random seed.\n",
        "def seed_all(seed: int) -> None:\n",
        "    \"\"\"Set all relevant seed for training a Pytorch Model.\n",
        "\n",
        "    Based on the following post:\n",
        "    https://discuss.pytorch.org/t/reproducibility-with-all-the-bells-and-whistles/81097\n",
        "    \"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "def seed_worker(worker_id: int) -> None:\n",
        "    \"\"\"Set seed for dataloader worker.\n",
        "\n",
        "    Based on the following post:\n",
        "    https://discuss.pytorch.org/t/reproducibility-with-all-the-bells-and-whistles/81097\n",
        "    \"\"\"\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "U78Ab64Lfz55",
      "metadata": {
        "id": "U78Ab64Lfz55"
      },
      "outputs": [],
      "source": [
        "# Create the Dataset and Dataloader + Log input to ðŸ”­ðŸŒ• Galileo\n",
        "\n",
        "# Create Dataset\n",
        "import os\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "\n",
        "image_crop_size = [224, 224]\n",
        "\n",
        "transform = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.Resize(image_crop_size),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Resize(image_crop_size),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "    }\n",
        "\n",
        "root_data_dir = os.path.abspath(LOCAL_DATA_DIR)\n",
        "TRAIN_SPLIT_NAME = \"train\"\n",
        "train_dataset = ImageFolder(root=f\"{root_data_dir}/ImageNet10_animals_train_val/train\", transform=transform[\"train\"])\n",
        "VAL_SPLIT_NAME = \"validation\" # this var is needed in dq.set_split down below\n",
        "val_dataset = ImageFolder(root=f\"{root_data_dir}/ImageNet10_animals_train_val/val\", transform=transform[\"val\"])\n",
        "\n",
        "print(f\"Loaded {TRAIN_SPLIT_NAME} dataset with {len(train_dataset)} samples and {len(train_dataset.classes)} labels\")\n",
        "print(f\"Loaded {VAL_SPLIT_NAME} dataset with {len(val_dataset)} samples and  {len(val_dataset.classes)} labels\")\n",
        "\n",
        "# Fix Labels: The labels of ImageNet are hashes. Convert to human readable labels\n",
        "CLASSES_DICT = {'n02124075' : 'Egyptian_cat', 'n02107574': 'Greater_Swiss_Mountain_dog', 'n02114367': 'Timber_wolf', 'n02085620': 'Chihuahua', 'n02114548': 'White_wolf', 'n02117135': 'Hyena', 'n02108915': 'French_bulldog', 'n02123159': 'Tiger_cat', 'n02114855': 'Coyote', 'n02106550': 'Rottweiler'}\n",
        "list_of_labels = [CLASSES_DICT[cls] for cls in train_dataset.classes]\n",
        "train_dataset.class_to_idx = {lab:i for i, lab in enumerate(list_of_labels)}\n",
        "val_dataset.class_to_idx = {lab:i for i, lab in enumerate(list_of_labels)}\n",
        "\n",
        "# ðŸ”­ðŸŒ• Galileo log: Set labels\n",
        "dq.set_labels_for_run(list_of_labels)\n",
        "\n",
        "# ðŸ”­ðŸŒ• Galileo log: Log dataset\n",
        "dq.log_image_dataset(train_dataset, split=TRAIN_SPLIT_NAME, imgs_remote=\"gs://galileo-public-data/CV_datasets/ImageNet10_animals_train_val/train\")\n",
        "dq.log_image_dataset(val_dataset, split=VAL_SPLIT_NAME, imgs_remote=\"gs://galileo-public-data/CV_datasets/ImageNet10_animals_train_val/val\")\n",
        "\n",
        "# Create Dataloader\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "NUM_WORKERS = 0 \n",
        "SEED_WORKER = 42\n",
        "\n",
        "seed_all(SEED_WORKER)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, worker_init_fn=seed_worker, pin_memory=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, worker_init_fn=seed_worker, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7-Xf3dvhm-HX",
      "metadata": {
        "cellView": "form",
        "id": "7-Xf3dvhm-HX"
      },
      "outputs": [],
      "source": [
        "#@markdown Visualize the Data.\n",
        "# Visualizing a few images of the dataset (post-processing/augmentation)\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import make_grid\n",
        "idxs = [random.randint(0, len(train_dataset) -1) for _ in range(20)]\n",
        "grid_img = make_grid([train_dataset[idx][0] for idx in idxs], nrow=5)\n",
        "plt.figure(figsize = (20,10))\n",
        "plt.imshow(grid_img.permute(1, 2, 0))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-kGDPjuvs-Zf",
      "metadata": {
        "id": "-kGDPjuvs-Zf"
      },
      "source": [
        "# 5. Log model data with Galileo\n",
        "\n",
        "Model data is logged by wrapping the model with `watch` function. This step will log the model logits and embeddings. You can achieve this by adding 1 line of code to the standard pytorch model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4D5jtbAMtCTj",
      "metadata": {
        "id": "4D5jtbAMtCTj"
      },
      "outputs": [],
      "source": [
        "from transformers import ViTForImageClassification\n",
        "\n",
        "model = ViTForImageClassification.from_pretrained(\n",
        "    \"google/vit-base-patch16-224-in21k\",\n",
        "    num_labels=len(list_of_labels),\n",
        "    id2label={str(i): c for i, c in enumerate(list_of_labels)},\n",
        "    label2id={c: str(i) for i, c in enumerate(list_of_labels)},\n",
        "    ignore_mismatched_sizes = True,\n",
        ").to(device)\n",
        "\n",
        "# ðŸ”­ðŸŒ• Galileo logging -- Watch model\n",
        "from dataquality.integrations.torch import watch\n",
        "watch(\n",
        "    model=model,\n",
        "    classifier_layer=model.classifier,\n",
        "    dataloaders=[train_dataloader, val_dataloader],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "knpdaq7YBmmo",
      "metadata": {
        "id": "knpdaq7YBmmo"
      },
      "source": [
        "# 6. Putting into Action: Training a Model\n",
        "\n",
        "We complete the training pipeline by using a standard PyTorch training setup. To complete logging, we call `dq.finish()` after training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uyisccqdW6rj",
      "metadata": {
        "id": "uyisccqdW6rj"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from time import sleep, time\n",
        "\n",
        "EPOCHS = 3\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5, weight_decay=5e-4)\n",
        "\n",
        "# Train !\n",
        "start = time()\n",
        "print(f\"Training for {EPOCHS} epochs on {device}\")\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    print(f\"Epoch {epoch}/{EPOCHS}\")\n",
        "    dq.set_epoch(epoch)  # ðŸ”­ðŸŒ• Galileo -- Set split\n",
        "\n",
        "    model.train()\n",
        "    train_loss = torch.tensor(0.0, device=device)\n",
        "    train_correct = torch.tensor(0, device=device)\n",
        "    \n",
        "    dq.set_split(TRAIN_SPLIT_NAME)\n",
        "    with tqdm(train_dataloader, unit=\"batch\") as train_minibatchs:\n",
        "        for train_minibatch in train_minibatchs:\n",
        "            train_minibatchs.set_description(f\"Epoch {epoch}\")\n",
        "\n",
        "            images = train_minibatch[0].to(device)\n",
        "            labels = train_minibatch[1].to(device)\n",
        "\n",
        "            preds = model(pixel_values=images, labels=labels)\n",
        "            logits, loss = preds.logits, preds.loss\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                train_loss += loss\n",
        "                train_batch_correct = (torch.argmax(logits, dim=1) == labels).sum()\n",
        "                train_correct += train_batch_correct\n",
        "\n",
        "            train_minibatchs.set_postfix(batch_loss=loss.item(), batch_accuracy=float(train_batch_correct) / BATCH_SIZE)\n",
        "            sleep(0.001)\n",
        "\n",
        "    print(f\"Training loss: {train_loss:.2f}\")\n",
        "    print(f\"Training accuracy: {100 * float(train_correct) / len(train_dataloader.dataset):.2f}\")\n",
        "    \n",
        "    dq.set_split(VAL_SPLIT_NAME)  # ðŸ”­ðŸŒ• Galileo -- Set split\n",
        "    if val_dataloader is not None:\n",
        "        model.eval()\n",
        "        val_loss = torch.tensor(0.0, device=device)\n",
        "        val_correct = torch.tensor(0, device=device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for val_minibatch in tqdm(val_dataloader):\n",
        "                images = val_minibatch[0].to(device)\n",
        "                labels = val_minibatch[1].to(device)\n",
        "                \n",
        "                preds = model(pixel_values=images, labels=labels)\n",
        "                logits, loss = preds.logits, preds.loss\n",
        "\n",
        "                val_loss += loss\n",
        "                val_correct += (torch.argmax(logits, dim=1) == labels).sum()\n",
        "\n",
        "        print(f\"{VAL_SPLIT_NAME} loss: {val_loss:.2f}\")\n",
        "        print(f\"{VAL_SPLIT_NAME} accuracy: {100*val_correct/len(val_dataloader.dataset):.2f}\")\n",
        "\n",
        "end = time()\n",
        "print(f\"Total training time: {end-start:.1f} seconds\")\n",
        "dq.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xRUq_rJ3Aiow",
      "metadata": {
        "id": "xRUq_rJ3Aiow"
      },
      "source": [
        "# General Help and Docs\n",
        "- To get help with your task's requirements, call `dq.get_data_logger().doc()`\n",
        "- To see more general data and model logging docs, run `dq.docs()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cp76O3rIAiBE",
      "metadata": {
        "id": "cp76O3rIAiBE"
      },
      "outputs": [],
      "source": [
        "dq.get_data_logger().doc()\n",
        "help(dq.log_dataset)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
