{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "499756e1",
      "metadata": {
        "id": "499756e1"
      },
      "source": [
        "# üìò Galileo + OpenTelemetry Tracing Guide (Python)\n",
        "\n",
        "This notebook demonstrates how to send OpenTelemetry traces to Galileo using OpenInference.\n",
        "\n",
        "üîó See full documentation [here](https://v2galileo.mintlify.app/guides/logs/otel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22f46309",
      "metadata": {
        "id": "22f46309"
      },
      "outputs": [],
      "source": [
        "!pip install -U \\\n",
        "    groq \\\n",
        "    openinference-instrumentation-groq \\\n",
        "    opentelemetry-sdk \\\n",
        "    opentelemetry-exporter-otlp \\\n",
        "    opentelemetry-api \\\n",
        "    \"opentelemetry-proto>=1.12.0\" -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LqWTc3tThcT2",
      "metadata": {
        "id": "LqWTc3tThcT2"
      },
      "outputs": [],
      "source": [
        "GALILEO_API_KEY = \"YOUR_API_KEY\"\n",
        "PROJECT_NAME = \"YOUR-PROJECT-NAME\"\n",
        "LOG_STREAM_NAME = \"my_log_stream\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f66cba4",
      "metadata": {
        "id": "8f66cba4"
      },
      "source": [
        "## üîê Authentication and Header Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af423957",
      "metadata": {
        "id": "af423957"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "headers = {\n",
        "    \"Galileo-API-Key\": GALILEO_API_KEY,\n",
        "    \"project\": PROJECT_NAME,\n",
        "    \"logstream\": LOG_STREAM_NAME,\n",
        "}\n",
        "# Format headers as a comma-separated key=value string\n",
        "# Example: Galileo-API-Key=abc123,project_name=my_project,log_stream_name=my_run\n",
        "os.environ['OTEL_EXPORTER_OTLP_TRACES_HEADERS'] = \",\".join([f\"{k}={v}\" for k, v in headers.items()])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af3f8236",
      "metadata": {
        "id": "af3f8236"
      },
      "source": [
        "## ‚öôÔ∏è OpenTelemetry Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db985591",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db985591",
        "outputId": "62e7aeec-d33d-45cb-b157-dc4423e7b542"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OTEL tracing initialized.\n"
          ]
        }
      ],
      "source": [
        "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
        "from opentelemetry.sdk import trace as trace_sdk\n",
        "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
        "\n",
        "from openinference.instrumentation.groq import GroqInstrumentor\n",
        "endpoint = \"https://app.galileo.ai/api/galileo/otel/traces\"\n",
        "tracer_provider = trace_sdk.TracerProvider()\n",
        "tracer_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter(endpoint)))\n",
        "\n",
        "GroqInstrumentor().instrument(tracer_provider=tracer_provider)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-UzqOCdGfqLv",
      "metadata": {
        "id": "-UzqOCdGfqLv"
      },
      "outputs": [],
      "source": [
        "from groq import AsyncGroq, Groq\n",
        "from groq.types.chat import ChatCompletionToolMessageParam\n",
        "\n",
        "client = Groq(\n",
        "        api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
        "    )\n",
        "\n",
        "    weather_function = {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_weather\",\n",
        "            \"description\": \"finds the weather for a given city\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"city\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The city to find the weather for, e.g. 'London'\",\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"city\"],\n",
        "            },\n",
        "        },\n",
        "    }\n",
        "\n",
        "    sys_prompt = \"Respond to the user's query using the correct tool.\"\n",
        "    user_msg = \"What's the weather like in San Francisco?\"\n",
        "\n",
        "    messages = [{\"role\": \"system\", \"content\": sys_prompt}, {\"role\": \"user\", \"content\": user_msg}]\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"mixtral-8x7b-32768\",\n",
        "        messages=messages,\n",
        "        temperature=0.0,\n",
        "        tools=[weather_function],\n",
        "        tool_choice=\"required\",\n",
        "    )\n",
        "\n",
        "    message = response.choices[0].message\n",
        "    assert (tool_calls := message.tool_calls)\n",
        "    tool_call_id = tool_calls[0].id\n",
        "    messages.append(message)\n",
        "    messages.append(\n",
        "        ChatCompletionToolMessageParam(content=\"sunny\", role=\"tool\", tool_call_id=tool_call_id),\n",
        "    )\n",
        "    final_response = client.chat.completions.create(\n",
        "        model=\"mixtral-8x7b-32768\",\n",
        "        messages=messages,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MOLrqdrt0Cuy",
      "metadata": {
        "id": "MOLrqdrt0Cuy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
