{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "499756e1",
      "metadata": {
        "id": "499756e1"
      },
      "source": [
        "# üìò Galileo + OpenTelemetry Tracing Guide (Python)\n",
        "\n",
        "This notebook demonstrates how to send OpenTelemetry traces to Galileo using OpenInference.\n",
        "\n",
        "üîó See full documentation [here](https://v2galileo.mintlify.app/guides/logs/otel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22f46309",
      "metadata": {
        "id": "22f46309"
      },
      "outputs": [],
      "source": [
        "!pip install -U \\\n",
        "    crewai \\\n",
        "    crewai_tools \\\n",
        "    openinference-instrumentation-crewai \\\n",
        "    openinference-instrumentation-litellm \\\n",
        "    openinference-instrumentation-langchain \\\n",
        "    opentelemetry-sdk \\\n",
        "    opentelemetry-exporter-otlp \\\n",
        "    opentelemetry-api \\\n",
        "    \"opentelemetry-proto>=1.12.0\"  -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LqWTc3tThcT2",
      "metadata": {
        "id": "LqWTc3tThcT2"
      },
      "outputs": [],
      "source": [
        "GALILEO_API_KEY = \"YOUR_API_KEY\"\n",
        "PROJECT_NAME = \"YOUR-PROJECT-NAME\"\n",
        "LOG_STREAM_NAME = \"my_log_stream\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f66cba4",
      "metadata": {
        "id": "8f66cba4"
      },
      "source": [
        "## üîê Authentication and Header Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af423957",
      "metadata": {
        "id": "af423957"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "headers = {\n",
        "    \"Galileo-API-Key\": GALILEO_API_KEY,\n",
        "    \"project\": PROJECT_NAME,\n",
        "    \"logstream\": LOG_STREAM_NAME,\n",
        "}\n",
        "# Format headers as a comma-separated key=value string\n",
        "# Example: Galileo-API-Key=abc123,project_name=my_project,log_stream_name=my_run\n",
        "os.environ['OTEL_EXPORTER_OTLP_TRACES_HEADERS'] = \",\".join([f\"{k}={v}\" for k, v in headers.items()])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af3f8236",
      "metadata": {
        "id": "af3f8236"
      },
      "source": [
        "## ‚öôÔ∏è OpenTelemetry Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db985591",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db985591",
        "outputId": "62e7aeec-d33d-45cb-b157-dc4423e7b542"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OTEL tracing initialized.\n"
          ]
        }
      ],
      "source": [
        "from opentelemetry.sdk import trace as trace_sdk\n",
        "from opentelemetry import trace as trace_api\n",
        "from opentelemetry.sdk.trace.export import BatchSpanProcessor, ConsoleSpanExporter\n",
        "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
        "from openinference.instrumentation.crewai import CrewAIInstrumentor\n",
        "from openinference.instrumentation.litellm import LiteLLMInstrumentor\n",
        "\n",
        "# OTEL endpoint for Galileo\n",
        "endpoint = \"https://app.galileo.ai/api/galileo/otel/traces\"\n",
        "\n",
        "# Setup tracer provider\n",
        "tracer_provider = trace_sdk.TracerProvider()\n",
        "tracer_provider.add_span_processor(BatchSpanProcessor(OTLPSpanExporter(endpoint)))\n",
        "\n",
        "# Optional: log locally\n",
        "tracer_provider.add_span_processor(BatchSpanProcessor(ConsoleSpanExporter()))\n",
        "\n",
        "# Register the provider\n",
        "trace_api.set_tracer_provider(tracer_provider=tracer_provider)\n",
        "\n",
        "# CrewAI Instrument (0.63.0 and above uses litellm)\n",
        "LiteLLMInstrumentor().instrument(tracer_provider=tracer_provider)\n",
        "CrewAIInstrumentor().instrument(skip_dep_check=True, tracer_provider=tracer_provider)\n",
        "\n",
        "print(\"CrewAI OTEL tracing initialized.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc64f4ae",
      "metadata": {},
      "source": [
        "# Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-UzqOCdGfqLv",
      "metadata": {
        "id": "-UzqOCdGfqLv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "    from google.colab import userdata\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "except:\n",
        "  print(\"Please set the  OPENAI_API_KEY variable\")\n",
        "from crewai import Agent, Crew, Process, Task\n",
        "\n",
        "# Define your agents with roles and goals\n",
        "researcher = Agent(\n",
        "    role=\"Senior Research Analyst\",\n",
        "    goal=\"Uncover cutting-edge developments in AI and data science\",\n",
        "    backstory=\"\"\"You work at a leading tech think tank.\n",
        "  Your expertise lies in identifying emerging trends.\n",
        "  You have a knack for dissecting complex data and presenting actionable insights.\"\"\",\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    # You can pass an optional llm attribute specifying what model you wanna use.\n",
        "    # llm=ChatOpenAI(model_name=\"gpt-3.5\", temperature=0.7),\n",
        ")\n",
        "writer = Agent(\n",
        "    role=\"Tech Content Strategist\",\n",
        "    goal=\"Craft compelling content on tech advancements\",\n",
        "    backstory=\"\"\"You are a renowned Content Strategist, known for your insightful and engaging articles.\n",
        "  You transform complex concepts into compelling narratives.\"\"\",\n",
        "    verbose=True,\n",
        "    allow_delegation=True,\n",
        ")\n",
        "\n",
        "# Create tasks for your agents\n",
        "task1 = Task(\n",
        "    description=\"\"\"Conduct a comprehensive analysis of the latest advancements in AI in 2024.\n",
        "  Identify key trends, breakthrough technologies, and potential industry impacts.\"\"\",\n",
        "    expected_output=\"Full analysis report in bullet points\",\n",
        "    agent=researcher,\n",
        ")\n",
        "\n",
        "task2 = Task(\n",
        "    description=\"\"\"Using the insights provided, develop an engaging blog\n",
        "  post that highlights the most significant AI advancements.\n",
        "  Your post should be informative yet accessible, catering to a tech-savvy audience.\n",
        "  Make it sound cool, avoid complex words so it doesn't sound like AI.\"\"\",\n",
        "    expected_output=\"Full blog post of at least 4 paragraphs\",\n",
        "    agent=writer,\n",
        ")\n",
        "\n",
        "# Instantiate your crew with a sequential process\n",
        "crew = Crew(\n",
        "    agents=[researcher, writer], tasks=[task1, task2], verbose=1, process=Process.sequential\n",
        ")\n",
        "\n",
        "# Get your crew to work!\n",
        "result = crew.kickoff()\n",
        "\n",
        "print(\"######################\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MOLrqdrt0Cuy",
      "metadata": {
        "id": "MOLrqdrt0Cuy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
