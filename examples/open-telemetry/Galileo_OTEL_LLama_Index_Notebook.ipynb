{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "499756e1",
      "metadata": {
        "id": "499756e1"
      },
      "source": [
        "# ðŸ“˜ Galileo + OpenTelemetry Tracing Guide (Python)\n",
        "\n",
        "This notebook demonstrates how to send OpenTelemetry traces to Galileo using OpenInference.\n",
        "\n",
        "ðŸ”— See full documentation [here](https://v2galileo.mintlify.app/guides/logs/otel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22f46309",
      "metadata": {
        "id": "22f46309"
      },
      "outputs": [],
      "source": [
        "pip install -U \\\n",
        "    llama-index \\\n",
        "    openinference-instrumentation-llama-index \\\n",
        "    opentelemetry-sdk \\\n",
        "    opentelemetry-exporter-otlp \\\n",
        "    opentelemetry-api \\\n",
        "    \"opentelemetry-proto>=1.12.0\" -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LqWTc3tThcT2",
      "metadata": {
        "id": "LqWTc3tThcT2"
      },
      "outputs": [],
      "source": [
        "GALILEO_API_KEY = \"YOUR_API_KEY\"\n",
        "PROJECT_NAME = \"YOUR-PROJECT-NAME\"\n",
        "LOG_STREAM_NAME = \"my_log_stream\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f66cba4",
      "metadata": {
        "id": "8f66cba4"
      },
      "source": [
        "## ðŸ” Authentication and Header Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af423957",
      "metadata": {
        "id": "af423957"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "headers = {\n",
        "    \"Galileo-API-Key\": GALILEO_API_KEY,\n",
        "    \"project\": PROJECT_NAME,\n",
        "    \"logstream\": LOG_STREAM_NAME,\n",
        "}\n",
        "# Format headers as a comma-separated key=value string\n",
        "# Example: Galileo-API-Key=abc123,project_name=my_project,log_stream_name=my_run\n",
        "os.environ['OTEL_EXPORTER_OTLP_TRACES_HEADERS'] = \",\".join([f\"{k}={v}\" for k, v in headers.items()])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af3f8236",
      "metadata": {
        "id": "af3f8236"
      },
      "source": [
        "## âš™ï¸ OpenTelemetry Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db985591",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db985591",
        "outputId": "62e7aeec-d33d-45cb-b157-dc4423e7b542"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OTEL tracing initialized.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
        "from opentelemetry.sdk import trace as trace_sdk\n",
        "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
        "\n",
        "from openinference.instrumentation.llama_index import LlamaIndexInstrumentor\n",
        "\n",
        "endpoint = \"https://app.galileo.ai/api/galileo/otel/traces\"\n",
        "tracer_provider = trace_sdk.TracerProvider()\n",
        "tracer_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter(endpoint)))\n",
        "\n",
        "LlamaIndexInstrumentor().instrument(tracer_provider=tracer_provider)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MOLrqdrt0Cuy",
      "metadata": {
        "id": "MOLrqdrt0Cuy"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from llama_index.agent.openai import OpenAIAgent\n",
        "from llama_index.core import Settings\n",
        "from llama_index.core.tools import FunctionTool\n",
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiple two integers and returns the result integer\"\"\"\n",
        "    return a * b\n",
        "\n",
        "\n",
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"Add two integers and returns the result integer\"\"\"\n",
        "    return a + b\n",
        "\n",
        "\n",
        "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
        "add_tool = FunctionTool.from_defaults(fn=add)\n",
        "agent = OpenAIAgent.from_tools([multiply_tool, add_tool])\n",
        "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
        "\n",
        "response = agent.query(\"What is (121 * 3) + 42?\")\n",
        "print(response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
